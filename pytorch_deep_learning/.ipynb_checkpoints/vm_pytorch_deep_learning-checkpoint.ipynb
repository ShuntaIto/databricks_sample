{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single node deep learning sample \n",
    "\n",
    "- Databricks Runtime 5.1 ML,GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare storage\n",
    "https://docs.azuredatabricks.net/applications/deep-learning/distributed-deep-learning/ddl-storage.html#ddl-fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUSE_DIR = 'horovod_pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare network with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### senseless big network to challenge the limit of GPU-Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BigNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 1000)\n",
    "        self.fc2 = nn.Linear(1000,5000)\n",
    "        self.fc3 = nn.Linear(5000,10000)\n",
    "        self.fc4 = nn.Linear(10000,5000)\n",
    "        self.fc5 = nn.Linear(5000,1000)\n",
    "        self.fc6 = nn.Linear(1000,500)\n",
    "        self.fc7 = nn.Linear(500,100)\n",
    "        self.fc8 = nn.Linear(100,50)\n",
    "        self.fc9 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc9(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare functions to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, device, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if batch_idx % log_interval == 0:\n",
    "        #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #        epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "        #        100. * batch_idx / len(data_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "\n",
    "LOG_DIR = os.path.join(FUSE_DIR, str(time()), 'MNISTDemo')\n",
    "os.makedirs(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch):\n",
    "    filepath = LOG_DIR + '/checkpoint-{epoch}.pth.tar'.format(epoch=epoch)\n",
    "    state = {'model': model.state_dict(),'optimizer': optimizer.state_dict(),}\n",
    "    torch.save(state, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "\n",
    "def train(learning_rate,small=True):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_dataset = datasets.MNIST(\n",
    "        'data', \n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "    data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    if small:\n",
    "        model = Net().to(device)\n",
    "    else:\n",
    "        model = BigNet().to(device)\n",
    "  \n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    for epoch in tqdm.trange(1, num_epochs + 1):\n",
    "        train_one_epoch(model, device, data_loader, optimizer, epoch)\n",
    "        save_checkpoint(model, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40min parameter, may over-fit \n",
    "batch_size = 100\n",
    "num_epochs = 300\n",
    "momentum = 0.5\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]\u001b[A/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "  0%|          | 1/300 [00:08<44:38,  8.96s/it]\u001b[A\n",
      "  1%|          | 2/300 [00:17<44:28,  8.95s/it]\u001b[A\n",
      "  1%|          | 3/300 [00:26<44:18,  8.95s/it]\u001b[A\n",
      "  1%|▏         | 4/300 [00:35<43:59,  8.92s/it]\u001b[A\n",
      "  2%|▏         | 5/300 [00:44<43:57,  8.94s/it]\u001b[A\n",
      "  2%|▏         | 6/300 [00:53<43:46,  8.94s/it]\u001b[A\n",
      "  2%|▏         | 7/300 [01:02<43:39,  8.94s/it]\u001b[A\n",
      "  3%|▎         | 8/300 [01:11<43:29,  8.94s/it]\u001b[A\n",
      "  3%|▎         | 9/300 [01:20<43:20,  8.94s/it]\u001b[A\n",
      "  3%|▎         | 10/300 [01:29<43:09,  8.93s/it]\u001b[A\n",
      "  4%|▎         | 11/300 [01:38<43:03,  8.94s/it]\u001b[A\n",
      "  4%|▍         | 12/300 [01:47<42:53,  8.94s/it]\u001b[A\n",
      "  4%|▍         | 13/300 [01:56<42:44,  8.93s/it]\u001b[A\n",
      "  5%|▍         | 14/300 [02:05<42:36,  8.94s/it]\u001b[A\n",
      "  5%|▌         | 15/300 [02:14<42:27,  8.94s/it]\u001b[A\n",
      "  5%|▌         | 16/300 [02:22<42:19,  8.94s/it]\u001b[A\n",
      "  6%|▌         | 17/300 [02:31<42:12,  8.95s/it]\u001b[A\n",
      "  6%|▌         | 18/300 [02:40<42:05,  8.95s/it]\u001b[A\n",
      "  6%|▋         | 19/300 [02:49<41:57,  8.96s/it]\u001b[A\n",
      "  7%|▋         | 20/300 [02:58<41:48,  8.96s/it]\u001b[A\n",
      "  7%|▋         | 21/300 [03:07<41:37,  8.95s/it]\u001b[A\n",
      "  7%|▋         | 22/300 [03:16<41:27,  8.95s/it]\u001b[A\n",
      "  8%|▊         | 23/300 [03:25<41:15,  8.94s/it]\u001b[A\n",
      "  8%|▊         | 24/300 [03:34<40:59,  8.91s/it]\u001b[A\n",
      "  8%|▊         | 25/300 [03:43<40:45,  8.89s/it]\u001b[A\n",
      "  9%|▊         | 26/300 [03:52<40:33,  8.88s/it]\u001b[A\n",
      "  9%|▉         | 27/300 [04:01<40:28,  8.89s/it]\u001b[A\n",
      "  9%|▉         | 28/300 [04:10<40:18,  8.89s/it]\u001b[A\n",
      " 10%|▉         | 29/300 [04:18<40:12,  8.90s/it]\u001b[A\n",
      " 10%|█         | 30/300 [04:27<40:01,  8.89s/it]\u001b[A\n",
      " 10%|█         | 31/300 [04:36<39:49,  8.88s/it]\u001b[A\n",
      " 11%|█         | 32/300 [04:45<39:43,  8.89s/it]\u001b[A\n",
      " 11%|█         | 33/300 [04:54<39:40,  8.92s/it]\u001b[A\n",
      " 11%|█▏        | 34/300 [05:03<39:29,  8.91s/it]\u001b[A\n",
      " 12%|█▏        | 35/300 [05:12<39:11,  8.87s/it]\u001b[A\n",
      " 12%|█▏        | 36/300 [05:21<39:04,  8.88s/it]\u001b[A\n",
      " 12%|█▏        | 37/300 [05:30<39:00,  8.90s/it]\u001b[A\n",
      " 13%|█▎        | 38/300 [05:38<38:50,  8.89s/it]\u001b[A\n",
      " 13%|█▎        | 39/300 [05:47<38:43,  8.90s/it]\u001b[A\n",
      " 13%|█▎        | 40/300 [05:56<38:38,  8.92s/it]\u001b[A\n",
      " 14%|█▎        | 41/300 [06:05<38:22,  8.89s/it]\u001b[A\n",
      " 14%|█▍        | 42/300 [06:14<38:17,  8.91s/it]\u001b[A\n",
      " 14%|█▍        | 43/300 [06:23<38:10,  8.91s/it]\u001b[A\n",
      " 15%|█▍        | 44/300 [06:32<38:03,  8.92s/it]\u001b[A\n",
      " 15%|█▌        | 45/300 [06:41<37:48,  8.90s/it]\u001b[A\n",
      " 15%|█▌        | 46/300 [06:50<37:38,  8.89s/it]\u001b[A\n",
      " 16%|█▌        | 47/300 [06:59<37:30,  8.90s/it]\u001b[A\n",
      " 16%|█▌        | 48/300 [07:08<37:24,  8.91s/it]\u001b[A\n",
      " 16%|█▋        | 49/300 [07:16<37:16,  8.91s/it]\u001b[A\n",
      " 17%|█▋        | 50/300 [07:25<37:04,  8.90s/it]\u001b[A\n",
      " 17%|█▋        | 51/300 [07:34<36:57,  8.91s/it]\u001b[A\n",
      " 17%|█▋        | 52/300 [07:43<36:52,  8.92s/it]\u001b[A\n",
      " 18%|█▊        | 53/300 [07:52<36:39,  8.91s/it]\u001b[A\n",
      " 18%|█▊        | 54/300 [08:01<36:33,  8.92s/it]\u001b[A\n",
      " 18%|█▊        | 55/300 [08:10<36:28,  8.93s/it]\u001b[A\n",
      " 19%|█▊        | 56/300 [08:19<36:20,  8.94s/it]\u001b[A\n",
      " 19%|█▉        | 57/300 [08:28<36:10,  8.93s/it]\u001b[A\n",
      " 19%|█▉        | 58/300 [08:37<36:02,  8.94s/it]\u001b[A\n",
      " 20%|█▉        | 59/300 [08:46<35:51,  8.93s/it]\u001b[A\n",
      " 20%|██        | 60/300 [08:55<35:40,  8.92s/it]\u001b[A\n",
      " 20%|██        | 61/300 [09:04<35:34,  8.93s/it]\u001b[A\n",
      " 21%|██        | 62/300 [09:12<35:25,  8.93s/it]\u001b[A\n",
      " 21%|██        | 63/300 [09:21<35:16,  8.93s/it]\u001b[A\n",
      " 21%|██▏       | 64/300 [09:30<35:06,  8.92s/it]\u001b[A\n",
      " 22%|██▏       | 65/300 [09:39<35:00,  8.94s/it]\u001b[A\n",
      " 22%|██▏       | 66/300 [09:48<34:43,  8.90s/it]\u001b[A\n",
      " 22%|██▏       | 67/300 [09:57<34:42,  8.94s/it]\u001b[A\n",
      " 23%|██▎       | 68/300 [10:06<34:29,  8.92s/it]\u001b[A\n",
      " 23%|██▎       | 69/300 [10:15<34:20,  8.92s/it]\u001b[A\n",
      " 23%|██▎       | 70/300 [10:24<34:14,  8.93s/it]\u001b[A\n",
      " 24%|██▎       | 71/300 [10:33<34:06,  8.94s/it]\u001b[A\n",
      " 24%|██▍       | 72/300 [10:42<33:54,  8.92s/it]\u001b[A\n",
      " 24%|██▍       | 73/300 [10:51<33:48,  8.93s/it]\u001b[A\n",
      " 25%|██▍       | 74/300 [11:00<33:39,  8.94s/it]\u001b[A\n",
      " 25%|██▌       | 75/300 [11:09<33:32,  8.95s/it]\u001b[A\n",
      " 25%|██▌       | 76/300 [11:18<33:21,  8.94s/it]\u001b[A\n",
      " 26%|██▌       | 77/300 [11:26<33:09,  8.92s/it]\u001b[A\n",
      " 26%|██▌       | 78/300 [11:35<33:02,  8.93s/it]\u001b[A\n",
      " 26%|██▋       | 79/300 [11:44<32:59,  8.96s/it]\u001b[A\n",
      " 27%|██▋       | 80/300 [11:53<32:41,  8.92s/it]\u001b[A\n",
      " 27%|██▋       | 81/300 [12:02<32:26,  8.89s/it]\u001b[A\n",
      " 27%|██▋       | 82/300 [12:11<32:23,  8.92s/it]\u001b[A\n",
      " 28%|██▊       | 83/300 [12:20<32:14,  8.92s/it]\u001b[A\n",
      " 28%|██▊       | 84/300 [12:29<32:02,  8.90s/it]\u001b[A\n",
      " 28%|██▊       | 85/300 [12:38<31:56,  8.91s/it]\u001b[A\n",
      " 29%|██▊       | 86/300 [12:47<31:47,  8.91s/it]\u001b[A\n",
      " 29%|██▉       | 87/300 [12:56<31:40,  8.92s/it]\u001b[A\n",
      " 29%|██▉       | 88/300 [13:05<31:32,  8.93s/it]\u001b[A\n",
      " 30%|██▉       | 89/300 [13:13<31:27,  8.95s/it]\u001b[A\n",
      " 30%|███       | 90/300 [13:22<31:19,  8.95s/it]\u001b[A\n",
      " 30%|███       | 91/300 [13:31<31:11,  8.95s/it]\u001b[A\n",
      " 31%|███       | 92/300 [13:40<31:02,  8.95s/it]\u001b[A\n",
      " 31%|███       | 93/300 [13:49<30:52,  8.95s/it]\u001b[A\n",
      " 31%|███▏      | 94/300 [13:58<30:40,  8.93s/it]\u001b[A\n",
      " 32%|███▏      | 95/300 [14:07<30:31,  8.93s/it]\u001b[A\n",
      " 32%|███▏      | 96/300 [14:16<30:21,  8.93s/it]\u001b[A\n",
      " 32%|███▏      | 97/300 [14:25<30:08,  8.91s/it]\u001b[A\n",
      " 33%|███▎      | 98/300 [14:34<29:56,  8.89s/it]\u001b[A\n",
      " 33%|███▎      | 99/300 [14:43<29:45,  8.88s/it]\u001b[A\n",
      " 33%|███▎      | 100/300 [14:51<29:32,  8.86s/it]\u001b[A\n",
      " 34%|███▎      | 101/300 [15:00<29:20,  8.85s/it]\u001b[A\n",
      " 34%|███▍      | 102/300 [15:09<29:11,  8.85s/it]\u001b[A\n",
      " 34%|███▍      | 103/300 [15:18<29:07,  8.87s/it]\u001b[A\n",
      " 35%|███▍      | 104/300 [15:27<28:54,  8.85s/it]\u001b[A\n",
      " 35%|███▌      | 105/300 [15:36<28:43,  8.84s/it]\u001b[A\n",
      " 35%|███▌      | 106/300 [15:45<28:42,  8.88s/it]\u001b[A\n",
      " 36%|███▌      | 107/300 [15:54<28:36,  8.89s/it]\u001b[A\n",
      " 36%|███▌      | 108/300 [16:02<28:29,  8.90s/it]\u001b[A\n",
      " 36%|███▋      | 109/300 [16:11<28:23,  8.92s/it]\u001b[A\n",
      " 37%|███▋      | 110/300 [16:20<28:13,  8.91s/it]\u001b[A\n",
      " 37%|███▋      | 111/300 [16:29<27:58,  8.88s/it]\u001b[A\n",
      " 37%|███▋      | 112/300 [16:38<27:49,  8.88s/it]\u001b[A\n",
      " 38%|███▊      | 113/300 [16:47<27:42,  8.89s/it]\u001b[A\n",
      " 38%|███▊      | 114/300 [16:56<27:32,  8.89s/it]\u001b[A\n",
      " 38%|███▊      | 115/300 [17:05<27:23,  8.89s/it]\u001b[A\n",
      " 39%|███▊      | 116/300 [17:14<27:18,  8.90s/it]\u001b[A\n",
      " 39%|███▉      | 117/300 [17:23<27:13,  8.92s/it]\u001b[A\n",
      " 39%|███▉      | 118/300 [17:32<27:02,  8.92s/it]\u001b[A\n",
      " 40%|███▉      | 119/300 [17:40<26:52,  8.91s/it]\u001b[A\n",
      " 40%|████      | 120/300 [17:49<26:48,  8.94s/it]\u001b[A\n",
      " 40%|████      | 121/300 [17:58<26:37,  8.92s/it]\u001b[A\n",
      " 41%|████      | 122/300 [18:07<26:23,  8.90s/it]\u001b[A\n",
      " 41%|████      | 123/300 [18:16<26:11,  8.88s/it]\u001b[A\n",
      " 41%|████▏     | 124/300 [18:25<26:04,  8.89s/it]\u001b[A\n",
      " 42%|████▏     | 125/300 [18:34<25:57,  8.90s/it]\u001b[A\n",
      " 42%|████▏     | 126/300 [18:43<25:50,  8.91s/it]\u001b[A\n",
      " 42%|████▏     | 127/300 [18:52<25:43,  8.92s/it]\u001b[A\n",
      " 43%|████▎     | 128/300 [19:01<25:37,  8.94s/it]\u001b[A\n",
      " 43%|████▎     | 129/300 [19:10<25:27,  8.93s/it]\u001b[A\n",
      " 43%|████▎     | 130/300 [19:18<25:11,  8.89s/it]\u001b[A\n",
      " 44%|████▎     | 131/300 [19:27<25:01,  8.88s/it]\u001b[A\n",
      " 44%|████▍     | 132/300 [19:36<24:52,  8.88s/it]\u001b[A\n",
      " 44%|████▍     | 133/300 [19:45<24:42,  8.88s/it]\u001b[A\n",
      " 45%|████▍     | 134/300 [19:54<24:36,  8.90s/it]\u001b[A\n",
      " 45%|████▌     | 135/300 [20:03<24:30,  8.91s/it]\u001b[A\n",
      " 45%|████▌     | 136/300 [20:12<24:22,  8.92s/it]\u001b[A\n",
      " 46%|████▌     | 137/300 [20:21<24:13,  8.92s/it]\u001b[A\n",
      " 46%|████▌     | 138/300 [20:30<23:58,  8.88s/it]\u001b[A\n",
      " 46%|████▋     | 139/300 [20:38<23:49,  8.88s/it]\u001b[A\n",
      " 47%|████▋     | 140/300 [20:47<23:43,  8.90s/it]\u001b[A\n",
      " 47%|████▋     | 141/300 [20:56<23:35,  8.90s/it]\u001b[A\n",
      " 47%|████▋     | 142/300 [21:05<23:30,  8.93s/it]\u001b[A\n",
      " 48%|████▊     | 143/300 [21:14<23:18,  8.91s/it]\u001b[A\n",
      " 48%|████▊     | 144/300 [21:23<23:09,  8.90s/it]\u001b[A\n",
      " 48%|████▊     | 145/300 [21:32<23:03,  8.92s/it]\u001b[A\n",
      " 49%|████▊     | 146/300 [21:41<22:56,  8.94s/it]\u001b[A\n",
      " 49%|████▉     | 147/300 [21:50<22:43,  8.91s/it]\u001b[A\n",
      " 49%|████▉     | 148/300 [21:59<22:36,  8.92s/it]\u001b[A\n",
      " 50%|████▉     | 149/300 [22:08<22:24,  8.91s/it]\u001b[A\n",
      " 50%|█████     | 150/300 [22:16<22:10,  8.87s/it]\u001b[A\n",
      " 50%|█████     | 151/300 [22:25<22:04,  8.89s/it]\u001b[A\n",
      " 51%|█████     | 152/300 [22:34<21:52,  8.87s/it]\u001b[A\n",
      " 51%|█████     | 153/300 [22:43<21:43,  8.87s/it]\u001b[A\n",
      " 51%|█████▏    | 154/300 [22:52<21:33,  8.86s/it]\u001b[A\n",
      " 52%|█████▏    | 155/300 [23:01<21:24,  8.86s/it]\u001b[A\n",
      " 52%|█████▏    | 156/300 [23:10<21:15,  8.86s/it]\u001b[A\n",
      " 52%|█████▏    | 157/300 [23:18<21:09,  8.87s/it]\u001b[A\n",
      " 53%|█████▎    | 158/300 [23:27<21:01,  8.88s/it]\u001b[A\n",
      " 53%|█████▎    | 159/300 [23:36<20:53,  8.89s/it]\u001b[A\n",
      " 53%|█████▎    | 160/300 [23:45<20:46,  8.90s/it]\u001b[A\n",
      " 54%|█████▎    | 161/300 [23:54<20:37,  8.90s/it]\u001b[A\n",
      " 54%|█████▍    | 162/300 [24:03<20:25,  8.88s/it]\u001b[A\n",
      " 54%|█████▍    | 163/300 [24:12<20:15,  8.87s/it]\u001b[A\n",
      " 55%|█████▍    | 164/300 [24:21<20:08,  8.89s/it]\u001b[A\n",
      " 55%|█████▌    | 165/300 [24:30<20:00,  8.89s/it]\u001b[A\n",
      " 55%|█████▌    | 166/300 [24:39<19:51,  8.89s/it]\u001b[A\n",
      " 56%|█████▌    | 167/300 [24:47<19:45,  8.91s/it]\u001b[A\n",
      " 56%|█████▌    | 168/300 [24:56<19:37,  8.92s/it]\u001b[A\n",
      " 56%|█████▋    | 169/300 [25:05<19:25,  8.90s/it]\u001b[A\n",
      " 57%|█████▋    | 170/300 [25:14<19:14,  8.88s/it]\u001b[A\n",
      " 57%|█████▋    | 171/300 [25:23<19:10,  8.92s/it]\u001b[A\n",
      " 57%|█████▋    | 172/300 [25:32<19:02,  8.93s/it]\u001b[A\n",
      " 58%|█████▊    | 173/300 [25:41<18:53,  8.93s/it]\u001b[A\n",
      " 58%|█████▊    | 174/300 [25:50<18:42,  8.91s/it]\u001b[A\n",
      " 58%|█████▊    | 175/300 [25:59<18:31,  8.89s/it]\u001b[A\n",
      " 59%|█████▊    | 176/300 [26:08<18:24,  8.91s/it]\u001b[A\n",
      " 59%|█████▉    | 177/300 [26:17<18:16,  8.92s/it]\u001b[A\n",
      " 59%|█████▉    | 178/300 [26:26<18:09,  8.93s/it]\u001b[A\n",
      " 60%|█████▉    | 179/300 [26:35<18:02,  8.94s/it]\u001b[A\n",
      " 60%|██████    | 180/300 [26:43<17:50,  8.92s/it]\u001b[A\n",
      " 60%|██████    | 181/300 [26:52<17:41,  8.92s/it]\u001b[A\n",
      " 61%|██████    | 182/300 [27:01<17:35,  8.94s/it]\u001b[A\n",
      " 61%|██████    | 183/300 [27:10<17:28,  8.97s/it]\u001b[A\n",
      " 61%|██████▏   | 184/300 [27:19<17:19,  8.96s/it]\u001b[A\n",
      " 62%|██████▏   | 185/300 [27:28<17:09,  8.95s/it]\u001b[A\n",
      " 62%|██████▏   | 186/300 [27:37<16:59,  8.94s/it]\u001b[A\n",
      " 62%|██████▏   | 187/300 [27:46<16:47,  8.92s/it]\u001b[A\n",
      " 63%|██████▎   | 188/300 [27:55<16:38,  8.91s/it]\u001b[A\n",
      " 63%|██████▎   | 189/300 [28:04<16:24,  8.87s/it]\u001b[A\n",
      " 63%|██████▎   | 190/300 [28:13<16:18,  8.90s/it]\u001b[A\n",
      " 64%|██████▎   | 191/300 [28:22<16:10,  8.90s/it]\u001b[A\n",
      " 64%|██████▍   | 192/300 [28:30<16:02,  8.91s/it]\u001b[A\n",
      " 64%|██████▍   | 193/300 [28:39<15:53,  8.91s/it]\u001b[A\n",
      " 65%|██████▍   | 194/300 [28:48<15:45,  8.92s/it]\u001b[A\n",
      " 65%|██████▌   | 195/300 [28:57<15:38,  8.93s/it]\u001b[A\n",
      " 65%|██████▌   | 196/300 [29:06<15:29,  8.94s/it]\u001b[A\n",
      " 66%|██████▌   | 197/300 [29:15<15:21,  8.95s/it]\u001b[A\n",
      " 66%|██████▌   | 198/300 [29:24<15:10,  8.93s/it]\u001b[A\n",
      " 66%|██████▋   | 199/300 [29:33<15:00,  8.91s/it]\u001b[A\n",
      " 67%|██████▋   | 200/300 [29:42<14:51,  8.92s/it]\u001b[A\n",
      " 67%|██████▋   | 201/300 [29:51<14:43,  8.92s/it]\u001b[A\n",
      " 67%|██████▋   | 202/300 [30:00<14:34,  8.93s/it]\u001b[A\n",
      " 68%|██████▊   | 203/300 [30:09<14:26,  8.93s/it]\u001b[A\n",
      " 68%|██████▊   | 204/300 [30:18<14:16,  8.92s/it]\u001b[A\n",
      " 68%|██████▊   | 205/300 [30:27<14:07,  8.92s/it]\u001b[A\n",
      " 69%|██████▊   | 206/300 [30:35<13:59,  8.93s/it]\u001b[A\n",
      " 69%|██████▉   | 207/300 [30:44<13:50,  8.93s/it]\u001b[A\n",
      " 69%|██████▉   | 208/300 [30:53<13:42,  8.93s/it]\u001b[A\n",
      " 70%|██████▉   | 209/300 [31:02<13:33,  8.94s/it]\u001b[A\n",
      " 70%|███████   | 210/300 [31:11<13:23,  8.92s/it]\u001b[A\n",
      " 70%|███████   | 211/300 [31:20<13:15,  8.94s/it]\u001b[A\n",
      " 71%|███████   | 212/300 [31:29<13:05,  8.93s/it]\u001b[A\n",
      " 71%|███████   | 213/300 [31:38<12:57,  8.93s/it]\u001b[A\n",
      " 71%|███████▏  | 214/300 [31:47<12:49,  8.95s/it]\u001b[A\n",
      " 72%|███████▏  | 215/300 [31:56<12:40,  8.95s/it]\u001b[A\n",
      " 72%|███████▏  | 216/300 [32:05<12:30,  8.93s/it]\u001b[A\n",
      " 72%|███████▏  | 217/300 [32:14<12:22,  8.95s/it]\u001b[A\n",
      " 73%|███████▎  | 218/300 [32:23<12:14,  8.96s/it]\u001b[A\n",
      " 73%|███████▎  | 219/300 [32:32<12:02,  8.92s/it]\u001b[A\n",
      " 73%|███████▎  | 220/300 [32:41<11:53,  8.91s/it]\u001b[A\n",
      " 74%|███████▎  | 221/300 [32:49<11:43,  8.90s/it]\u001b[A\n",
      " 74%|███████▍  | 222/300 [32:58<11:35,  8.92s/it]\u001b[A\n",
      " 74%|███████▍  | 223/300 [33:07<11:26,  8.92s/it]\u001b[A\n",
      " 75%|███████▍  | 224/300 [33:16<11:18,  8.93s/it]\u001b[A\n",
      " 75%|███████▌  | 225/300 [33:25<11:08,  8.92s/it]\u001b[A\n",
      " 75%|███████▌  | 226/300 [33:34<10:57,  8.88s/it]\u001b[A\n",
      " 76%|███████▌  | 227/300 [33:43<10:46,  8.86s/it]\u001b[A\n",
      " 76%|███████▌  | 228/300 [33:52<10:37,  8.85s/it]\u001b[A\n",
      " 76%|███████▋  | 229/300 [34:01<10:29,  8.87s/it]\u001b[A\n",
      " 77%|███████▋  | 230/300 [34:09<10:21,  8.88s/it]\u001b[A\n",
      " 77%|███████▋  | 231/300 [34:18<10:13,  8.88s/it]\u001b[A\n",
      " 77%|███████▋  | 232/300 [34:27<10:02,  8.86s/it]\u001b[A\n",
      " 78%|███████▊  | 233/300 [34:36<09:52,  8.84s/it]\u001b[A\n",
      " 78%|███████▊  | 234/300 [34:45<09:42,  8.82s/it]\u001b[A\n",
      " 78%|███████▊  | 235/300 [34:54<09:34,  8.84s/it]\u001b[A\n",
      " 79%|███████▊  | 236/300 [35:02<09:25,  8.83s/it]\u001b[A\n",
      " 79%|███████▉  | 237/300 [35:11<09:19,  8.87s/it]\u001b[A\n",
      " 79%|███████▉  | 238/300 [35:20<09:11,  8.90s/it]\u001b[A\n",
      " 80%|███████▉  | 239/300 [35:29<09:04,  8.93s/it]\u001b[A\n",
      " 80%|████████  | 240/300 [35:38<08:54,  8.91s/it]\u001b[A\n",
      " 80%|████████  | 241/300 [35:47<08:44,  8.89s/it]\u001b[A\n",
      " 81%|████████  | 242/300 [35:56<08:33,  8.85s/it]\u001b[A\n",
      " 81%|████████  | 243/300 [36:05<08:25,  8.87s/it]\u001b[A\n",
      " 81%|████████▏ | 244/300 [36:14<08:17,  8.89s/it]\u001b[A\n",
      " 82%|████████▏ | 245/300 [36:23<08:09,  8.91s/it]\u001b[A\n",
      " 82%|████████▏ | 246/300 [36:31<08:00,  8.90s/it]\u001b[A\n",
      " 82%|████████▏ | 247/300 [36:40<07:52,  8.92s/it]\u001b[A\n",
      " 83%|████████▎ | 248/300 [36:49<07:43,  8.91s/it]\u001b[A\n",
      " 83%|████████▎ | 249/300 [36:58<07:34,  8.90s/it]\u001b[A\n",
      " 83%|████████▎ | 250/300 [37:07<07:23,  8.87s/it]\u001b[A\n",
      " 84%|████████▎ | 251/300 [37:16<07:14,  8.86s/it]\u001b[A\n",
      " 84%|████████▍ | 252/300 [37:25<07:06,  8.88s/it]\u001b[A\n",
      " 84%|████████▍ | 253/300 [37:34<06:57,  8.87s/it]\u001b[A\n",
      " 85%|████████▍ | 254/300 [37:42<06:47,  8.85s/it]\u001b[A\n",
      " 85%|████████▌ | 255/300 [37:51<06:39,  8.88s/it]\u001b[A\n",
      " 85%|████████▌ | 256/300 [38:00<06:31,  8.89s/it]\u001b[A\n",
      " 86%|████████▌ | 257/300 [38:09<06:22,  8.90s/it]\u001b[A\n",
      " 86%|████████▌ | 258/300 [38:18<06:13,  8.89s/it]\u001b[A\n",
      " 86%|████████▋ | 259/300 [38:27<06:04,  8.90s/it]\u001b[A\n",
      " 87%|████████▋ | 260/300 [38:36<05:55,  8.88s/it]\u001b[A\n",
      " 87%|████████▋ | 261/300 [38:45<05:46,  8.89s/it]\u001b[A\n",
      " 87%|████████▋ | 262/300 [38:54<05:37,  8.88s/it]\u001b[A\n",
      " 88%|████████▊ | 263/300 [39:02<05:26,  8.83s/it]\u001b[A\n",
      " 88%|████████▊ | 264/300 [39:11<05:18,  8.85s/it]\u001b[A\n",
      " 88%|████████▊ | 265/300 [39:20<05:10,  8.86s/it]\u001b[A\n",
      " 89%|████████▊ | 266/300 [39:29<05:00,  8.84s/it]\u001b[A\n",
      " 89%|████████▉ | 267/300 [39:38<04:51,  8.83s/it]\u001b[A\n",
      " 89%|████████▉ | 268/300 [39:47<04:43,  8.87s/it]\u001b[A\n",
      " 90%|████████▉ | 269/300 [39:55<04:34,  8.85s/it]\u001b[A\n",
      " 90%|█████████ | 270/300 [40:04<04:25,  8.86s/it]\u001b[A\n",
      " 90%|█████████ | 271/300 [40:13<04:17,  8.89s/it]\u001b[A\n",
      " 91%|█████████ | 272/300 [40:22<04:09,  8.89s/it]\u001b[A\n",
      " 91%|█████████ | 273/300 [40:31<03:59,  8.88s/it]\u001b[A\n",
      " 91%|█████████▏| 274/300 [40:40<03:51,  8.90s/it]\u001b[A\n",
      " 92%|█████████▏| 275/300 [40:49<03:42,  8.92s/it]\u001b[A\n",
      " 92%|█████████▏| 276/300 [40:58<03:33,  8.92s/it]\u001b[A\n",
      " 92%|█████████▏| 277/300 [41:07<03:25,  8.92s/it]\u001b[A\n",
      " 93%|█████████▎| 278/300 [41:16<03:15,  8.89s/it]\u001b[A\n",
      " 93%|█████████▎| 279/300 [41:24<03:06,  8.88s/it]\u001b[A\n",
      " 93%|█████████▎| 280/300 [41:33<02:57,  8.89s/it]\u001b[A\n",
      " 94%|█████████▎| 281/300 [41:42<02:48,  8.88s/it]\u001b[A\n",
      " 94%|█████████▍| 282/300 [41:51<02:39,  8.88s/it]\u001b[A\n",
      " 94%|█████████▍| 283/300 [42:00<02:30,  8.87s/it]\u001b[A\n",
      " 95%|█████████▍| 284/300 [42:09<02:22,  8.88s/it]\u001b[A\n",
      " 95%|█████████▌| 285/300 [42:18<02:13,  8.88s/it]\u001b[A\n",
      " 95%|█████████▌| 286/300 [42:27<02:03,  8.85s/it]\u001b[A\n",
      " 96%|█████████▌| 287/300 [42:35<01:54,  8.84s/it]\u001b[A\n",
      " 96%|█████████▌| 288/300 [42:44<01:46,  8.84s/it]\u001b[A\n",
      " 96%|█████████▋| 289/300 [42:53<01:37,  8.87s/it]\u001b[A\n",
      " 97%|█████████▋| 290/300 [43:02<01:28,  8.90s/it]\u001b[A\n",
      " 97%|█████████▋| 291/300 [43:11<01:20,  8.90s/it]\u001b[A\n",
      " 97%|█████████▋| 292/300 [43:20<01:11,  8.90s/it]\u001b[A\n",
      " 98%|█████████▊| 293/300 [43:29<01:02,  8.86s/it]\u001b[A\n",
      " 98%|█████████▊| 294/300 [43:38<00:53,  8.86s/it]\u001b[A\n",
      " 98%|█████████▊| 295/300 [43:46<00:44,  8.86s/it]\u001b[A\n",
      " 99%|█████████▊| 296/300 [43:55<00:35,  8.90s/it]\u001b[A\n",
      " 99%|█████████▉| 297/300 [44:04<00:26,  8.91s/it]\u001b[A\n",
      " 99%|█████████▉| 298/300 [44:13<00:17,  8.92s/it]\u001b[A\n",
      "100%|█████████▉| 299/300 [44:22<00:08,  8.91s/it]\u001b[A\n",
      "100%|██████████| 300/300 [44:31<00:00,  8.90s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:2671.546637058258\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "train(learning_rate = 0.001)\n",
    "process_time = time.time() - start\n",
    "\n",
    "print(\"processing time:\"+str(process_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train senseless big network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting training parameters\n",
    "batch_size = 300\n",
    "num_epochs = 30\n",
    "momentum = 0.5\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "  3%|▎         | 1/30 [00:17<08:19, 17.21s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [00:34<08:00, 17.18s/it]\u001b[A\n",
      " 10%|█         | 3/30 [00:52<07:50, 17.44s/it]\u001b[A\n",
      " 13%|█▎        | 4/30 [01:09<07:30, 17.34s/it]\u001b[A\n",
      " 17%|█▋        | 5/30 [01:27<07:15, 17.42s/it]\u001b[A\n",
      " 20%|██        | 6/30 [01:44<06:59, 17.48s/it]\u001b[A\n",
      " 23%|██▎       | 7/30 [01:59<06:22, 16.65s/it]\u001b[A\n",
      " 27%|██▋       | 8/30 [02:14<05:53, 16.08s/it]\u001b[A\n",
      " 30%|███       | 9/30 [02:28<05:26, 15.54s/it]\u001b[A\n",
      " 33%|███▎      | 10/30 [02:43<05:06, 15.31s/it]\u001b[A\n",
      " 37%|███▋      | 11/30 [02:57<04:45, 15.01s/it]\u001b[A\n",
      " 40%|████      | 12/30 [03:12<04:27, 14.87s/it]\u001b[A\n",
      " 43%|████▎     | 13/30 [03:27<04:15, 15.01s/it]\u001b[A\n",
      " 47%|████▋     | 14/30 [03:42<03:59, 14.99s/it]\u001b[A\n",
      " 50%|█████     | 15/30 [03:57<03:47, 15.15s/it]\u001b[A\n",
      " 53%|█████▎    | 16/30 [04:13<03:33, 15.24s/it]\u001b[A\n",
      " 57%|█████▋    | 17/30 [04:28<03:18, 15.27s/it]\u001b[A\n",
      " 60%|██████    | 18/30 [04:44<03:04, 15.37s/it]\u001b[A\n",
      " 63%|██████▎   | 19/30 [04:59<02:49, 15.38s/it]\u001b[A\n",
      " 67%|██████▋   | 20/30 [05:14<02:31, 15.15s/it]\u001b[A\n",
      " 70%|███████   | 21/30 [05:28<02:14, 14.94s/it]\u001b[A\n",
      " 73%|███████▎  | 22/30 [05:43<01:59, 14.94s/it]\u001b[A\n",
      " 77%|███████▋  | 23/30 [05:58<01:44, 14.99s/it]\u001b[A\n",
      " 80%|████████  | 24/30 [06:13<01:29, 14.98s/it]\u001b[A\n",
      " 83%|████████▎ | 25/30 [06:29<01:16, 15.34s/it]\u001b[A\n",
      " 87%|████████▋ | 26/30 [06:45<01:01, 15.40s/it]\u001b[A\n",
      " 90%|█████████ | 27/30 [07:00<00:45, 15.31s/it]\u001b[A\n",
      " 93%|█████████▎| 28/30 [07:15<00:30, 15.11s/it]\u001b[A\n",
      " 97%|█████████▋| 29/30 [07:30<00:15, 15.17s/it]\u001b[A\n",
      "100%|██████████| 30/30 [07:45<00:00, 15.20s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:466.7347915172577\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(learning_rate = 0.001,small=False)\n",
    "process_time = time.time() - start\n",
    "\n",
    "print(\"processing time:\"+str(process_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "name": "PyTorch",
  "notebookId": 3388580873466386
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
